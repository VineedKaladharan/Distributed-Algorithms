1
00:00:02,639 --> 00:00:05,180
Welcome to the
Distributed Algorithms course

2
00:00:05,180 --> 00:00:07,120
at Aalto University!

3
00:00:07,120 --> 00:00:10,719
I'm Jukka Suomela and
I'm teaching this course

4
00:00:10,719 --> 00:00:12,970
together with Juho Hirvonen.

5
00:00:12,970 --> 00:00:18,920
Hello everyone, I'm Juho Hirvonen,
welcome also on my behalf!

6
00:00:18,920 --> 00:00:22,220
In this course we will study
theoretical computer science

7
00:00:22,220 --> 00:00:25,529
from a new perspective.

8
00:00:25,529 --> 00:00:29,589
Imagine you are a node
in the middle of a large graph.

9
00:00:29,589 --> 00:00:32,750
For example, think about
a computer network:

10
00:00:32,750 --> 00:00:37,079
each node is a computer,
each edge is a communication link.

11
00:00:37,079 --> 00:00:41,809
Or maybe it's a social network:
each node is a human being, and

12
00:00:41,809 --> 00:00:46,210
there are edges between
two people who know each other.

13
00:00:46,210 --> 00:00:49,890
Or maybe it's
a multicellular organism:

14
00:00:49,890 --> 00:00:53,710
each node is a cell, and
there is an edge between two cells

15
00:00:53,710 --> 00:00:58,910
that can exchange biochemical
signals with each other.

16
00:00:58,910 --> 00:01:01,949
No matter what's
the specific scenario,

17
00:01:01,949 --> 00:01:07,860
we will represent it as a graph,
in the usual mathematical sense.

18
00:01:07,860 --> 00:01:11,579
There is a set of nodes,
and there is a set of edges.

19
00:01:11,579 --> 00:01:13,720
And working together,

20
00:01:13,720 --> 00:01:17,970
the nodes are trying
to accomplish something.

21
00:01:17,970 --> 00:01:20,470
Maybe we need to find a tree
that can be used

22
00:01:20,470 --> 00:01:24,939
for spreading information,
for routing, and for navigation.

23
00:01:24,939 --> 00:01:31,259
Or maybe we need to form pairs for
collaboration and sharing resources.

24
00:01:31,259 --> 00:01:35,880
Or maybe we need to find
a coloring of the nodes.

25
00:01:35,880 --> 00:01:38,240
That is, label the nodes

26
00:01:38,240 --> 00:01:43,680
with colors so that neighboring
nodes have different colors.

27
00:01:43,680 --> 00:01:48,149
Why would we need to do this?

28
00:01:48,149 --> 00:01:50,280
It turns out that coloring

29
00:01:50,280 --> 00:01:55,969
is a very important primitive
especially in distributed systems.

30
00:01:55,969 --> 00:01:59,210
A coloring gives a schedule.

31
00:01:59,210 --> 00:02:02,409
For example, here we have

32
00:02:02,409 --> 00:02:06,930
a coloring with three colors,
red, green, and blue.

33
00:02:06,930 --> 00:02:12,470
We can first make red nodes active,
all other nodes are passive.

34
00:02:12,470 --> 00:02:17,290
Notice that the red nodes
form an independent set.

35
00:02:17,290 --> 00:02:22,230
If you look at any active node,
all of its neighbors are passive.

36
00:02:22,230 --> 00:02:26,980
So we will never have two
active nodes next to each other.

37
00:02:26,980 --> 00:02:30,180
Active nodes can safely do
whatever they want,

38
00:02:30,180 --> 00:02:31,709
without any risk that

39
00:02:31,709 --> 00:02:37,040
the actions of their neighbors
would conflict with them.

40
00:02:37,040 --> 00:02:42,599
Then we can make green nodes active,
all other nodes are passive.

41
00:02:42,599 --> 00:02:46,459
Then blue nodes are active,
all other nodes passive.

42
00:02:46,459 --> 00:02:51,670
And now we are done, each node
had an opportunity to be active.

43
00:02:51,670 --> 00:02:54,379
If we have a coloring with k colors,

44
00:02:54,379 --> 00:02:59,840
we can go through all color
classes in k time steps this way.

45
00:02:59,840 --> 00:03:03,010
So a coloring gives a schedule

46
00:03:03,010 --> 00:03:07,810
that we can use to coordinate
the actions of the nodes.

47
00:03:07,810 --> 00:03:12,090
And a coloring with a small
number of colors is good,

48
00:03:12,090 --> 00:03:18,459
because it gives a short schedule;
we can complete work quickly.

49
00:03:18,459 --> 00:03:19,930
So let's recap.

50
00:03:19,930 --> 00:03:24,720
We have a graph that
consists of nodes and edges.

51
00:03:24,720 --> 00:03:29,700
The nodes need to work together
to accomplish something.

52
00:03:29,700 --> 00:03:32,230
And we are
theoretical computer scientists,

53
00:03:32,230 --> 00:03:34,730
so we interpret this so that

54
00:03:34,730 --> 00:03:40,270
the nodes need to solve
some computational problem.

55
00:03:40,270 --> 00:03:42,989
Usually it's a graph problem.

56
00:03:42,989 --> 00:03:45,330
Finding a spanning tree.

57
00:03:45,330 --> 00:03:47,040
Finding a matching.

58
00:03:47,040 --> 00:03:49,659
Finding a proper vertex coloring.

59
00:03:49,659 --> 00:03:52,110
And so on.

60
00:03:52,110 --> 00:03:55,189
And we take
a distributed perspective.

61
00:03:55,189 --> 00:04:00,879
Initially, each node is
only aware of itself.

62
00:04:00,879 --> 00:04:02,360
And eventually

63
00:04:02,360 --> 00:04:07,510
each node needs to figure out
its own part of the solution.

64
00:04:07,510 --> 00:04:11,099
For example,
if we do graph coloring,

65
00:04:11,099 --> 00:04:16,329
each node needs to know
its own color.

66
00:04:16,329 --> 00:04:18,850
Let's go through this more
carefully, this is critical.

67
00:04:18,850 --> 00:04:20,180
This is the key difference

68
00:04:20,180 --> 00:04:23,230
between the theory of
distributed computing and

69
00:04:23,230 --> 00:04:27,510
the theory of classical,
centralized sequential computing.

70
00:04:27,510 --> 00:04:34,790
As I said, in the beginning
each node is only aware of itself.

71
00:04:34,790 --> 00:04:36,830
Nobody knows the whole graph.

72
00:04:36,830 --> 00:04:42,520
Here I know that I'm here a node
with five neighbors, that's it.

73
00:04:42,520 --> 00:04:47,370
I can exchange messages
with my neighbors to learn more.

74
00:04:47,370 --> 00:04:52,060
And of course
all other nodes can do the same.

75
00:04:52,060 --> 00:04:57,020
Everyone can talk to their
own neighbors to learn more.

76
00:04:57,020 --> 00:05:01,800
But we don't want to waste
too much time doing communication.

77
00:05:01,800 --> 00:05:05,190
Each communication step
takes some time.

78
00:05:05,190 --> 00:05:10,450
And we want to minimize
the number of communication rounds.

79
00:05:10,450 --> 00:05:15,000
So after some, ideally small
number of communication rounds

80
00:05:15,000 --> 00:05:17,910
we want to stop.

81
00:05:17,910 --> 00:05:19,550
And when we stop,

82
00:05:19,550 --> 00:05:25,280
each node has to figure out
its own part of the solution.

83
00:05:25,280 --> 00:05:27,070
If we are forming pairs,

84
00:05:27,070 --> 00:05:32,240
each node needs to know which
of the neighbors is its pair.

85
00:05:32,240 --> 00:05:33,810
If we do graph coloring,

86
00:05:33,810 --> 00:05:38,250
each node needs to know
its own color.

87
00:05:38,250 --> 00:05:43,550
And this is already enough for
each node to know what to do.

88
00:05:43,550 --> 00:05:47,470
For example, if we use
graph coloring for scheduling,

89
00:05:47,470 --> 00:05:51,560
if I know that my color is five,
I know that

90
00:05:51,560 --> 00:05:56,280
I can be safely active
during time slot number five.

91
00:05:56,280 --> 00:05:59,000
I don't need to know
everyone's colors,

92
00:05:59,000 --> 00:06:03,920
knowing my own color is enough
to know when to act.

93
00:06:03,920 --> 00:06:08,570
So this is what we study
in distributed algorithms.

94
00:06:08,570 --> 00:06:10,380
We are solving graph problems

95
00:06:10,380 --> 00:06:14,370
so that all nodes
take part in the computation.

96
00:06:14,370 --> 00:06:18,440
Both input and output
are distributed.

97
00:06:18,440 --> 00:06:21,660
Nobody knows the whole input.

98
00:06:21,660 --> 00:06:28,030
And each node only needs to know
its own part of the output.

99
00:06:28,030 --> 00:06:29,560
This is very different

100
00:06:29,560 --> 00:06:33,330
from classical theoretical
computer science, where

101
00:06:33,330 --> 00:06:36,700
we think that the whole input
is stored in one place,

102
00:06:36,700 --> 00:06:41,030
it is given to one computer
to be processed,

103
00:06:41,030 --> 00:06:45,300
and the whole output
is then returned back.

104
00:06:45,300 --> 00:06:48,340
Usually we don't even pay
any attention to this,

105
00:06:48,340 --> 00:06:52,880
but please note that this is
a very strong assumption.

106
00:06:52,880 --> 00:06:59,850
We assume someone knows perfectly
the entire state of the world!

107
00:06:59,850 --> 00:07:02,600
Someone knows the structure
of the whole Internet,

108
00:07:02,600 --> 00:07:07,310
or the structure of the global
social network, and so on.

109
00:07:07,310 --> 00:07:09,030
Also please note that

110
00:07:09,030 --> 00:07:13,500
this is different from
traditional parallel computing,

111
00:07:13,500 --> 00:07:18,140
where we may use multiple
processors to solve the problem,

112
00:07:18,140 --> 00:07:20,090
but we nevertheless have

113
00:07:20,090 --> 00:07:24,330
the full input stored
somewhere in one place

114
00:07:24,330 --> 00:07:30,350
and eventually we will store
the whole solution in one place.

115
00:07:30,350 --> 00:07:34,520
So in pretty much all other
areas of computer science

116
00:07:34,520 --> 00:07:37,900
you take an outsider's view.

117
00:07:37,900 --> 00:07:43,650
You are an all-seeing entity,
sitting somewhere outside your input.

118
00:07:43,650 --> 00:07:45,250
You know everything.

119
00:07:45,250 --> 00:07:49,800
The only question is what
to do with this information.

120
00:07:49,800 --> 00:07:55,620
While in distributed algorithms
we take an insider's view.

121
00:07:55,620 --> 00:07:59,020
We are sitting somewhere
in the middle of a graph,

122
00:07:59,020 --> 00:08:02,270
we are one of possibly
millions of nodes.

123
00:08:02,270 --> 00:08:04,721
And we have no idea
about the whole input.

124
00:08:04,721 --> 00:08:09,520
We can learn a bit more
by talking to our neighbors.

125
00:08:09,520 --> 00:08:12,830
But since we'd like to
solve problems fast,

126
00:08:12,830 --> 00:08:18,270
we usually don't want to wait
until everyone knows everything.

127
00:08:18,270 --> 00:08:22,370
So we'd like to be able to
produce at least our own part of

128
00:08:22,370 --> 00:08:28,900
the solution based on whatever
we see in our local neighborhood.

129
00:08:28,900 --> 00:08:33,820
And this turns out to be one of
the key concept that we want to

130
00:08:33,820 --> 00:08:38,460
understand in this course:
locality.

131
00:08:38,460 --> 00:08:44,010
Fast distributed algorithms are
necessarily highly localized.

132
00:08:44,010 --> 00:08:47,250
In a small number of
communication steps you can only

133
00:08:47,250 --> 00:08:50,840
get some information
from your local neighborhood.

134
00:08:50,840 --> 00:08:52,620
Why is this?

135
00:08:52,620 --> 00:08:57,330
Well, just imagine an algorithm
where in each round everyone

136
00:08:57,330 --> 00:09:02,480
tells all of its neighbors
everything it knows so far.

137
00:09:02,480 --> 00:09:05,970
Initially, everyone
just knows about itself.

138
00:09:05,970 --> 00:09:07,490
Then after one round

139
00:09:07,490 --> 00:09:11,420
everyone knows about everything
within distance one.

140
00:09:11,420 --> 00:09:13,390
After two rounds

141
00:09:13,390 --> 00:09:16,980
everyone knows about everything
within distance two.

142
00:09:16,980 --> 00:09:18,620
After three rounds

143
00:09:18,620 --> 00:09:21,390
everyone knows about everything
within distance three.

144
00:09:21,390 --> 00:09:22,840
And so on.

145
00:09:22,840 --> 00:09:27,310
So in T rounds everyone can know

146
00:09:27,310 --> 00:09:33,900
at best everything up to
distance T, and nothing more.

147
00:09:33,900 --> 00:09:38,130
If you stop after
a small number of rounds,

148
00:09:38,130 --> 00:09:39,180
whatever you output

149
00:09:39,180 --> 00:09:44,260
will only depend on
what you see close to you.

150
00:09:44,260 --> 00:09:50,210
Fast distributed algorithms are
necessarily also highly localized.

151
00:09:50,210 --> 00:09:54,570
And this is a key questions
we are going to ask,

152
00:09:54,570 --> 00:09:58,760
over and over again
during this course:

153
00:09:58,760 --> 00:10:00,510
When is this enough?

154
00:10:00,510 --> 00:10:04,220
What can you do
with only local information?

155
00:10:04,220 --> 00:10:07,750
And what cannot be
solved locally?

156
00:10:07,750 --> 00:10:09,380
Which graph problems are local?

157
00:10:09,380 --> 00:10:11,450
And which graph problems
are global?

158
00:10:11,450 --> 00:10:13,520
Or put otherwise,

159
00:10:13,520 --> 00:10:16,680
which problems can be solved
fast in a distributed setting,

160
00:10:16,680 --> 00:10:21,610
with only a small number of
communication rounds?

161
00:10:21,610 --> 00:10:28,270
And which problems necessarily
require a large number of rounds?

162
00:10:28,270 --> 00:10:30,310
So you can approach
these questions

163
00:10:30,310 --> 00:10:35,820
from a purely graph-theoretic
perspective if you prefer that.

164
00:10:35,820 --> 00:10:38,560
Or you can think about computers,
network connections,

165
00:10:38,560 --> 00:10:41,590
messages that you pass
between nodes,

166
00:10:41,590 --> 00:10:45,470
and algorithms that process
the messages, and so on.

167
00:10:45,470 --> 00:10:46,470
Whichever you do,

168
00:10:46,470 --> 00:10:50,690
you will get a new perspective
on the theory of computing.

169
00:10:50,690 --> 00:10:53,830
You will learn
to think like an insider,

170
00:10:53,830 --> 00:10:57,770
instead of thinking
like an outsider.

171
00:10:57,770 --> 00:11:00,160
So far in many other courses

172
00:11:00,160 --> 00:11:03,840
you have been reasoning about
computational operations.

173
00:11:03,840 --> 00:11:07,470
Like, how many arithmetic
operations or memory lookups

174
00:11:07,470 --> 00:11:10,610
or Turing machine steps
are needed to solve something.

175
00:11:10,610 --> 00:11:14,300
The key resource
has been computation.

176
00:11:14,300 --> 00:11:16,550
In this course we will study

177
00:11:16,550 --> 00:11:22,400
an entirely different kind of
resource: communication.

178
00:11:22,400 --> 00:11:24,170
We will look at questions like

179
00:11:24,170 --> 00:11:29,690
how many communication steps
are needed to solve something.

180
00:11:29,690 --> 00:11:32,440
And, if you look at

181
00:11:32,440 --> 00:11:35,420
real-world computer networks
in practice,

182
00:11:35,420 --> 00:11:40,010
you can see that communication
steps are usually very expensive

183
00:11:40,010 --> 00:11:43,920
in comparison with
computational steps.

184
00:11:43,920 --> 00:11:48,180
If you just try to get one bit
of data from another computer

185
00:11:48,180 --> 00:11:50,970
sitting in your local network,

186
00:11:50,970 --> 00:11:54,390
it'll take something like
half a millisecond.

187
00:11:54,390 --> 00:11:58,550
Half a millisecond
may not sound like much,

188
00:11:58,550 --> 00:12:01,450
until you check how many
arithmetic operations

189
00:12:01,450 --> 00:12:06,110
your computer could do
in half a millisecond.

190
00:12:06,110 --> 00:12:08,550
And even for your
old desktop computer

191
00:12:08,550 --> 00:12:12,220
the answer can be easily
one billion!

192
00:12:12,220 --> 00:12:15,760
So there can be a factor
one billion difference

193
00:12:15,760 --> 00:12:19,910
between the cost talking to
other computers

194
00:12:19,910 --> 00:12:25,110
and doing some number-crunching
inside one computer!

195
00:12:25,110 --> 00:12:30,090
So if you have a bunch of nodes
that are sitting in a network

196
00:12:30,090 --> 00:12:33,600
and that want to solve
something together,

197
00:12:33,600 --> 00:12:39,030
the key limitation is often
communication, not computation.

198
00:12:39,030 --> 00:12:40,980
And this is one of
the key reasons

199
00:12:40,980 --> 00:12:44,300
why I want to make sure
you learn

200
00:12:44,300 --> 00:12:49,490
how to design algorithms that
are communication-efficient.

201
00:12:49,490 --> 00:12:53,710
And we will also learn how to
prove negative results

202
00:12:53,710 --> 00:12:57,670
that tell us about
the fundamental limitations of

203
00:12:57,670 --> 00:13:01,120
computation in large networks.

204
00:13:01,120 --> 00:13:02,960
We will learn how to prove

205
00:13:02,960 --> 00:13:07,029
that some problems
are inherently global;

206
00:13:07,029 --> 00:13:12,340
we show that there is no way to
solve them in a small number of

207
00:13:12,340 --> 00:13:18,020
communication rounds, by using
only local information around you.

208
00:13:18,020 --> 00:13:23,260
And such results tell us something
fundamental about nature,

209
00:13:23,260 --> 00:13:26,970
as they apply to any system that

210
00:13:26,970 --> 00:13:31,250
consists of entities
that talk to each other.

211
00:13:31,250 --> 00:13:35,530
Not just about man-made systems,
like telecommunication networks.

212
00:13:35,530 --> 00:13:38,060
We can use the same principles to

213
00:13:38,060 --> 00:13:42,730
reason about biological systems
or social networks.

214
00:13:42,730 --> 00:13:44,310
We can apply what we learn here

215
00:13:44,310 --> 00:13:47,770
to study job markets
or animal populations.

216
00:13:47,770 --> 00:13:53,160
In particular, we can use
what we learn here to study

217
00:13:53,160 --> 00:13:57,670
the fundamental limitations
of such systems:

218
00:13:57,670 --> 00:14:01,480
what are things that
you cannot do quickly,

219
00:14:01,480 --> 00:14:05,550
no matter what kind of
a mechanism we use.

220
00:14:05,550 --> 00:14:10,690
So distributed computing
is not only about computers,

221
00:14:10,690 --> 00:14:12,260
it is very much about

222
00:14:12,260 --> 00:14:15,550
understanding the
mathematical foundations of

223
00:14:15,550 --> 00:14:20,600
all kinds of systems that
consist of interacting entities.

